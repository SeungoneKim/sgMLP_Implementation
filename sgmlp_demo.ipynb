{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c84fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae71aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import build_model\n",
    "model = build_model(tokenizer.vocab_size,512,2048,64,12,'cpu')\n",
    "weight = torch.load('iter_110000.pth',map_location=torch.device('cpu'))['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d59d8caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weight = {}\n",
    "for key,val in weight.items():\n",
    "    if key.startswith('module.'):\n",
    "        model_weight[key[7:]] = val\n",
    "    else:\n",
    "        print(key)\n",
    "model.load_state_dict(model_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63614d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text,model,tokenizer,max=64,mask='[MASK]'):\n",
    "     input  = tokenizer(text,max_length=max,padding='max_length',return_tensors='pt')\n",
    "     tokens = tokenizer.convert_ids_to_tokens(input['input_ids'].numpy().squeeze())\n",
    "     idx = tokens.index(mask)\n",
    "     output = model(input['input_ids'],input['token_type_ids']).squeeze()\n",
    "     masked_input = output[idx].detach().numpy()\n",
    "     predicted_vocab = np.argmax(masked_input)\n",
    "     predicted_vocab = tokenizer.convert_ids_to_tokens([predicted_vocab])\n",
    "     return predicted_vocab\n",
    "\n",
    "\n",
    "model= model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1a9b892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3327)\n",
      "tensor(0.6232)\n",
      "tensor(0.4975)\n",
      "tensor(0.4493)\n",
      "tensor(0.3444)\n",
      "tensor(0.6129)\n",
      "tensor(0.6101)\n",
      "tensor(0.3525)\n",
      "tensor(0.5657)\n",
      "tensor(0.6557)\n",
      "tensor(0.6757)\n",
      "tensor(0.2471)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['make']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'I want to [MASK] coffee.'\n",
    "inference(text,model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01bbf9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3345)\n",
      "tensor(0.5313)\n",
      "tensor(0.5038)\n",
      "tensor(0.4145)\n",
      "tensor(0.4530)\n",
      "tensor(0.5633)\n",
      "tensor(0.6120)\n",
      "tensor(0.4372)\n",
      "tensor(0.6078)\n",
      "tensor(0.6676)\n",
      "tensor(0.5590)\n",
      "tensor(0.2155)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['eat']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'I am hungry so I want to [MASK] steak.'\n",
    "inference(text,model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7d55345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3763)\n",
      "tensor(0.5854)\n",
      "tensor(0.2789)\n",
      "tensor(0.4430)\n",
      "tensor(0.4672)\n",
      "tensor(0.6326)\n",
      "tensor(0.6319)\n",
      "tensor(0.3933)\n",
      "tensor(0.4384)\n",
      "tensor(0.7933)\n",
      "tensor(0.6049)\n",
      "tensor(0.2452)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['is']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'This function [MASK] differentiable, so gradients will flow back from the result of this operation.'\n",
    "inference(text,model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab8fc7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3355)\n",
      "tensor(0.6006)\n",
      "tensor(0.3058)\n",
      "tensor(0.4079)\n",
      "tensor(0.4934)\n",
      "tensor(0.5693)\n",
      "tensor(0.6565)\n",
      "tensor(0.3596)\n",
      "tensor(0.4127)\n",
      "tensor(0.7644)\n",
      "tensor(0.6440)\n",
      "tensor(0.2778)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['will']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'This function is differentiable, so gradients [MASK] flow back from the result of this operation.'\n",
    "inference(text,model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cff3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
